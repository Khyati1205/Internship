{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "121bc73b",
   "metadata": {},
   "source": [
    "# Rainfall Weather Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c65b02",
   "metadata": {},
   "source": [
    "Rainfall Weather Forecasting\n",
    "\n",
    "Project Description\n",
    "Weather forecasting is the application of science and technology to predict the conditions of\n",
    "the atmosphere for a given location and time. Weather forecasts are made by\n",
    "collecting quantitative data about the current state of the atmosphere at a given place and\n",
    "using meteorology to project how the atmosphere will change.\n",
    "Rain Dataset is to predict whether or not it will rain tomorrow. The Dataset contains about 10\n",
    "years of daily weather observations of different locations in Australia. Here, predict two things:\n",
    " \n",
    "1. Problem Statement: \n",
    "a) Design a predictive model with the use of machine learning algorithms to forecast whether or\n",
    "not it will rain tomorrow.\n",
    "b)  Design a predictive model with the use of machine learning algorithms to predict how much\n",
    "rainfall could be there.\n",
    "\n",
    "Dataset Description:\n",
    "Number of columns: 23\n",
    "\n",
    "Date  - The date of observation\n",
    "Location  -The common name of the location of the weather station\n",
    "MinTemp  -The minimum temperature in degrees celsius\n",
    "MaxTemp -The maximum temperature in degrees celsius\n",
    "Rainfall  -The amount of rainfall recorded for the day in mm\n",
    "Evaporation  -The so-called Class A pan evaporation (mm) in the 24 hours to 9am\n",
    "Sunshine  -The number of hours of bright sunshine in the day.\n",
    "WindGustDi r- The direction of the strongest wind gust in the 24 hours to midnight\n",
    "WindGustSpeed -The speed (km/h) of the strongest wind gust in the 24 hours to midnight\n",
    "WindDir9am -Direction of the wind at 9am\n",
    "WindDir3pm -Direction of the wind at 3pm\n",
    "WindSpeed9am -Wind speed (km/hr) averaged over 10 minutes prior to 9am\n",
    "WindSpeed3pm -Wind speed (km/hr) averaged over 10 minutes prior to 3pm\n",
    "Humidity9am -Humidity (percent) at 9am\n",
    "\n",
    "Humidity3pm -Humidity (percent) at 3pm\n",
    "Pressure9am -Atmospheric pressure (hpa) reduced to mean sea level at 9am\n",
    "Pressure3pm -Atmospheric pressure (hpa) reduced to mean sea level at 3pm\n",
    "Cloud9am - Fraction of sky obscured by cloud at 9am. \n",
    "Cloud3pm -Fraction of sky obscured by cloud \n",
    "Temp9am-Temperature (degrees C) at 9am\n",
    "Temp3pm -Temperature (degrees C) at 3pm\n",
    "RainToday -Boolean: 1 if precipitation (mm) in the 24 hours to 9am exceeds 1mm, otherwise 0\n",
    "RainTomorrow -The amount of next day rain in mm. Used to create response variable . A kind of\n",
    "measure of the &quot;risk&quot;.\n",
    "\n",
    "Dataset Link-\n",
    " https://raw.githubusercontent.com/dsrscientist/dataset3/main/weatherAUS.csv\n",
    " https://github.com/dsrscientist/dataset3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30312013",
   "metadata": {},
   "source": [
    "https://raw.githubusercontent.com/dsrscientist/dataset3/main/weatherAUS.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdc0964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import warnings\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy import stats \n",
    "from scipy.stats import  zscore\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc24de1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the file. \n",
    "df = pd.read_csv('https://raw.githubusercontent.com/dsrscientist/dataset3/main/weatherAUS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064bedac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the first 5 rows and all columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e8cc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 rows from the last \n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64314fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30dd40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a3b788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the sum of the missing values\n",
    "df.isnull().sum().to_frame(\"No. of missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a704a0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the count of the missing values \n",
    "df.nunique().to_frame(\"No. of unique value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c86385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the heatmap to show the missing value\n",
    "sns.heatmap(df.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c61b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can identify that there are missing values in the heatmap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b004c80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check the percentage of the missing data. \n",
    "missing_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "print(missing_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0d41aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns: \n",
    "    print(f\"columns:{col}\")\n",
    "    print(df[col].value_counts())\n",
    "    print(\"/n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06df91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysing the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3fc254",
   "metadata": {},
   "source": [
    "- We can identy that there are only 2 types of data present in the df. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9bf423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# understanding the dataframe.\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a4deb3",
   "metadata": {},
   "source": [
    "Observation\n",
    "- Tmp ranges from -2 to 28.50, also in the 75% quantile and the max limit there is a huge gap, representing the outliers in the column. \n",
    "- The Max temp the lower value 23.857657 and the max value is 45, the outliers are seen in the column looking at the gap b/t the last quantile and the max value. \n",
    "- Very less values are observed between the min : -5.946275 and max : 107.000000 in the rainfall column, displaying the outliers\n",
    "- Left Skew : Min Temp, WindSpeed3pm, Humidity9am, Humidity3pm\n",
    "- Right Skew : Max Temp, Rainfall, WindGustSpeed, WindSpeed9am, Pressure9am, Pressure3pm, Temp9am, Temp3pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b483e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Rainfall over time\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(df['Rainfall'])\n",
    "plt.title('Rainfall Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Rainfall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee51c90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the 'Date' column to datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'], format= '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395e15fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the day, month, and year and create new columns for each\n",
    "df['Day'] = df['Date'].dt.day\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Year'] = df['Date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f191032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the datatype to date time format \n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc180c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to very the format\n",
    "print(df['Date'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45778ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will drop the columns since it has high number of missing data. \n",
    "df = df.drop(['Evaporation', 'Sunshine','Cloud9am','Cloud3pm','Date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3946a00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_col = []\n",
    "numerical_col = []\n",
    "\n",
    "# Categorize columns as categorical or numerical\n",
    "for i in df.columns:\n",
    "    if df.dtypes[i] == \"object\":\n",
    "        categorical_col.append(i)\n",
    "    else:\n",
    "        numerical_col.append(i)\n",
    "\n",
    "print(\"Categorical Columns:\", categorical_col)\n",
    "print(\"\\n\")\n",
    "print(\"Numerical Columns:\", numerical_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1128afda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique occurrences of each location\n",
    "location_counts = df['Location'].value_counts()\n",
    "\n",
    "# Plot pie chart\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.pie(location_counts, labels=location_counts.index, autopct='%1.1f%%')\n",
    "plt.axis('equal')\n",
    "plt.title('Pie chart of Locations')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa160c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the missing values from the categorical data. \n",
    "Missing_categorical = ['WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday', 'RainTomorrow']\n",
    "\n",
    "for column in Missing_categorical:\n",
    "    df[column].fillna(df[column].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef35a755",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  to check if the missing values are removed\n",
    "df['RainToday'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1683ccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Rainfall'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a781b843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the missing values in rainfall with mean\n",
    "mean_rainfall = df['Rainfall'].mean()\n",
    "df['Rainfall'].fillna(mean_rainfall, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf9763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Rainfall'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600ea4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working on the missing numerical values using the  IterativeImputer\n",
    "Missing_numerical = ['MinTemp', 'MaxTemp', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Temp9am', 'Temp3pm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5ed5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in Missing_numerical:\n",
    "    mean_value = df[col].mean()\n",
    "    df[col].fillna(mean_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419de1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378fcb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Rainfall'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75af743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Rain prediction\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.countplot(x='RainTomorrow', data=df)\n",
    "plt.title('Rainfall Distribution')\n",
    "print(df['RainTomorrow'].value_counts())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05b2bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Rainfall\n",
    "plt.figure(figsize=(25, 15))\n",
    "sns.distplot(df['Rainfall']) \n",
    "plt.title('Rainfall Distribution')\n",
    "print(df['Rainfall'].value_counts())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d147bee",
   "metadata": {},
   "source": [
    "- The data seems to be unbalanced we will have to balance the data in order to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62d5b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87931417",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "sns.countplot(x='Location', hue='RainTomorrow', data=df, palette=\"hls\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c670e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "sns.histplot(x='MinTemp', hue='RainTomorrow', bins=50, data=df, palette=\"hls\", multiple=\"stack\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8d27d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "sns.histplot(x='MaxTemp', hue='RainTomorrow', bins=100, data=df, palette=\"husl\", multiple=\"stack\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27abd329",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100, 80))\n",
    "sns.pairplot(df,hue=\"RainTomorrow\",palette=\"Set1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59ae2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the skewness\n",
    "df.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5581d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653534bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_col = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "plt.figure(figsize=(20,25), facecolor='green')\n",
    "plotnumber = 1\n",
    "\n",
    "for col in numerical_col:\n",
    "    if plotnumber <= 9:\n",
    "        ax = plt.subplot(4, 5, plotnumber)\n",
    "        sns.distplot(df[col])\n",
    "        plt.xlabel(col, fontsize=15)\n",
    "        plt.xticks(rotation=0, fontsize=10)\n",
    "        title = \"Skewness : %.2f\"%(df[col].skew())\n",
    "        plt.title(title, fontsize=15)\n",
    "        plotnumber += 1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1447968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b17b993",
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_col = ['Rainfall','WindGustSpeed','WindSpeed9am']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7edd813",
   "metadata": {},
   "source": [
    "from scipy.stats import yeojohnson\n",
    "# removing the skewness\n",
    "for col in skew_col:\n",
    "    df[col], _ = yeojohnson(df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5177f899",
   "metadata": {},
   "source": [
    "- We shall proceed without removing the skewness, since there are NaN values in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3c1a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd74036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the values of the categorical column\n",
    "le = LabelEncoder()\n",
    "for col in categorical_col:\n",
    "    df[col] = le.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103752d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a8841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for the outliers in the numderical columns\n",
    "numerical_col = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "plt.figure(figsize =(10,6))\n",
    "plotnumber = 1\n",
    "\n",
    "for col in numerical_col:\n",
    "    if plotnumber<=9:\n",
    "        ax = plt.subplot(4,5,plotnumber)\n",
    "        sns.boxplot(df[col])\n",
    "        plt.xlabel(col,fontsize=15)\n",
    "        plt.xticks(rotation=0,fontsize=10)\n",
    "    plotnumber+=1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3021b207",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore \n",
    "feature_outliers =(['Rainfall','WindGustSpeed','WindSpeed3pm','Humidity9am','Pressure9am'])\n",
    "Z = np.abs(zscore(df[feature_outliers]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d850430",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b3dc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping the threshold=3\n",
    "threshold = 3\n",
    "print(np.where(Z>3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59935262",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[(Z<3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310a7d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data Loss Percentage = \",((df.shape[0]-df1.shape[0])/df.shape[0])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889ac0d9",
   "metadata": {},
   "source": [
    "- We shall proceed with the original data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974fc685",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperating the features and the label. \n",
    "X1 = df1.drop('RainTomorrow', axis=1)\n",
    "Y1 = df1['RainTomorrow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b53498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing the data in to the training and the testing data. \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, Y1, test_size=0.2, random_state=22)\n",
    "X_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4772b0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X1_train_scaled = scaler.fit_transform(X_train)\n",
    "X1_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e052035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Create an instance of SMOTE\n",
    "smote = SMOTE()\n",
    "\n",
    "# Resample the data\n",
    "X1, Y1 = smote.fit_resample(X1,Y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa72850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cc0e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X1_train, X1_test, Y1_train, Y1_test = train_test_split(X1, Y1, test_size=0.2, random_state=22)\n",
    "X1_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f4e1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_score(clf, X1_train, X1_test, Y1_train, Y1_test, train):\n",
    "    if train == True: \n",
    "        pred = clf.predict(X1_train)\n",
    "        print(\"\\n======================Train Result==========================\")\n",
    "        print(f\"Accuracy Score : {accuracy_score(Y1_train, pred) * 100:.2f}%\")\n",
    "    elif train == False: \n",
    "        pred = clf.predict(X1_test)\n",
    "        print(\"\\n======================Test Result==========================\")\n",
    "        print(f\"Accuracy Score : {accuracy_score(Y1_test, pred) * 100:.2f}%\")\n",
    "        print('\\n \\n Test Classification Report \\n', classification_report(Y1_test, pred, digits=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4440881",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# training the model \n",
    "rf.fit(X1_train, Y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abe957b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_score(rf, X1_train, X1_test, Y1_train, Y1_test, train= True)\n",
    "metric_score(rf, X1_train, X1_test, Y1_train, Y1_test, train= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d62d020",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "# training the model \n",
    "lr.fit(X1_train, Y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217d1b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_score(lr, X1_train, X1_test, Y1_train, Y1_test, train= True)\n",
    "metric_score(lr, X1_train, X1_test, Y1_train, Y1_test, train= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3d9e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# training the model\n",
    "dt.fit(X1_train, Y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5841df87",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_score(dt, X1_train, X1_test, Y1_train, Y1_test, train= True)\n",
    "metric_score(dt, X1_train, X1_test, Y1_train, Y1_test, train= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c0439d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "# training the model\n",
    "gb.fit(X1_train, Y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c862ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_score(gb, X1_train, X1_test, Y1_train, Y1_test, train= True)\n",
    "metric_score(gb, X1_train, X1_test, Y1_train, Y1_test, train= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cc13f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = RandomForestClassifier(), GradientBoostingClassifier(), DecisionTreeClassifier(), LogisticRegression()\n",
    "model_names = ['RandomForestClassifier', 'GradientBoostingClassifier', 'DecisionTreeClassifier', 'LogisticRegression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21444161",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the models\n",
    "models = [RandomForestClassifier(), GradientBoostingClassifier(), DecisionTreeClassifier(), LogisticRegression()]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for model in models:\n",
    "    # Train the model\n",
    "    model.fit(X1_train, Y1_train)\n",
    "\n",
    "    # Predict probabilities\n",
    "    probabilities = model.predict_proba(X1_test)[:, 1]\n",
    "\n",
    "    # Compute ROC curve and AUC score\n",
    "    fpr, tpr, _ = roc_curve(Y1_test, probabilities)\n",
    "    auc_score = roc_auc_score(Y1_test, probabilities)\n",
    "\n",
    "    # Plot the ROC curve\n",
    "    plt.plot(fpr, tpr, label=f'{type(model).__name__} (AUC = {auc_score:.2f})')\n",
    "\n",
    "# Random guess line\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristics (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7738b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "models = [RandomForestClassifier(), GradientBoostingClassifier(), DecisionTreeClassifier(), LogisticRegression()]\n",
    "\n",
    "# For each model\n",
    "for model in models:\n",
    "    # Perform cross-validation\n",
    "    scores = cross_val_score(model, X1, Y1, cv=5)\n",
    "    \n",
    "    # Print cross-validation score for each model\n",
    "    print(f'{type(model).__name__}: {scores.mean():.2f} +/- {scores.std():.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e97b682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names of the models\n",
    "model_names = ['RandomForestClassifier', 'GradientBoostingClassifier', 'DecisionTreeClassifier', 'LogisticRegression']\n",
    "\n",
    "# Cross-validation scores\n",
    "cross_val_scores = [0.79, 0.65, 0.76, 0.71] # Replace these with your actual scores\n",
    "\n",
    "# Standard Deviation scores\n",
    "std_scores = [0.08, 0.07, 0.08, 0.06] # Replace these with your actual scores\n",
    "\n",
    "\n",
    "\n",
    "# Create a dataframe\n",
    "df = pd.DataFrame({\n",
    "    'Model': model_names,\n",
    "    'Cross_Val_Score': cross_val_scores,\n",
    "    'Std_Score': std_scores\n",
    "})\n",
    "\n",
    "# Print the dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f309bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestClassifier is the best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878f7143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "scores = cross_val_score(model, X1, Y1, cv=5)\n",
    "\n",
    "print(\"Cross-validation scores: \", scores)\n",
    "print(\"Average cross-validation score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca3e6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# Define a grid of hyperparameter 'params_\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200], \n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "grid_rf.fit(X1_train, Y1_train)\n",
    "print(\"Best parameters found: \", grid_rf.best_params_)\n",
    "print(\"Best score found: \", grid_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8377427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best parameters\n",
    "best_params = grid_rf.best_params_\n",
    "print(\"Best parameters found: \", best_params)\n",
    "\n",
    "# Get the best score\n",
    "best_score = grid_rf.best_score_\n",
    "print(\"Best score found: \", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4bd5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reffitting the model \n",
    "best_rf = RandomForestClassifier(**best_params)\n",
    "best_rf.fit(X1_train, Y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d371c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Predict the labels\n",
    "Y1_pred = best_rf.predict(X1_test)\n",
    "\n",
    "# Print accuracy score and classification report\n",
    "print(\"Accuracy Score : \", accuracy_score(Y1_test, Y1_pred))\n",
    "print(\"\\nClassification Report : \\n\", classification_report(Y1_test, Y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c84c496",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Predict= {'Location' : [3], \n",
    "               'MinTemp' : [13.4],\n",
    "               'MaxTemp'  : [22.9],\n",
    "               'Raifall'   : [0.6]\n",
    "               'WindGustDir' : [22.0],\n",
    "               'WindGustSpeed' :[1007.7],\n",
    "                'WindDir3pm' : [3],\n",
    "               'Windspeed9am' : [1.19],\n",
    "               'Windspeed3pm' : [13.00],\n",
    "               'WindDir9am' : [13],\n",
    "               'Humidity9am' : [4.0],\n",
    "               'Humidity3pm' : [25.0],\n",
    "               'Pressure9am' : ['1007.7'],\n",
    "               'Pressure3pm' : [1007.1],\n",
    "               'Temp9am' :  [16.9],\n",
    "               'Temp3pm' :  [21.8],\n",
    "               'RainTomorrow' : [1]}\n",
    "\n",
    "df_pred = pd.DataFrame(data_Predict,index=[0])\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a3e8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the result using the best model. \n",
    "new_pred = best_rfr.predict(df_pred)\n",
    "print(new_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3007aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8ab206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1414,
   "id": "cf4d85e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 2 : Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1415,
   "id": "3c21d48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1416,
   "id": "e931cdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = df1.drop(['Rainfall'],axis=1)\n",
    "y2 = df1['Rainfall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5f5760",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df,hue=\"Rainfall\",palette=\"Set1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5252be00",
   "metadata": {},
   "outputs": [],
   "source": [
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130be3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8e2741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X2_train, X2_test, Y2_train, Y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9bf43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "scaler = StandardScaler()\n",
    "X2_train_scaled = scaler.fit_transform(X2_train)\n",
    "X2_test_scaled = scaler.transform(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb8ac60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  training the data\n",
    "lr = LinearRegression()\n",
    "lr.fit(X2_train_scaled, Y2_train)\n",
    "\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X2_train_scaled, Y2_train)\n",
    "\n",
    "gr = GradientBoostingRegressor()\n",
    "gr.fit(X2_train_scaled, Y2_train)\n",
    "\n",
    "dt = DecisionTreeRegressor()\n",
    "dt.fit(X2_train_scaled, Y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b888a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions on the scaled test data\n",
    "lr_predictions = lr.predict(X2_test_scaled)\n",
    "rfr_predictions = rfr.predict(X2_test_scaled)\n",
    "gr_predictions = gr.predict(X2_test_scaled)\n",
    "dt_predictions = dt.predict(X2_test_scaled)\n",
    "\n",
    "# Evaluating the models\n",
    "lr_mse2 = mean_squared_error(Y2_test, lr_predictions)\n",
    "rfr_mse2 = mean_squared_error(Y2_test, rfr_predictions)\n",
    "gr_mse2 = mean_squared_error(Y2_test, gr_predictions)\n",
    "dt_mse2 = mean_squared_error(Y2_test, dt_predictions)\n",
    "\n",
    "lr_mae2 = mean_absolute_error(Y2_test, lr_predictions)\n",
    "rfr_mae2 = mean_absolute_error(Y2_test, rfr_predictions)\n",
    "gr_mae2 = mean_absolute_error(Y2_test, gr_predictions)\n",
    "dt_mae2 = mean_absolute_error(Y2_test, dt_predictions)\n",
    "\n",
    "lr_r2_2 = r2_score(Y2_test, lr_predictions)\n",
    "rfr_r2_2 = r2_score(Y2_test, rfr_predictions)\n",
    "gr_r2_2 = r2_score(Y2_test, gr_predictions)\n",
    "dt_r2_2 = r2_score(Y2_test, dt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6b3a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Mean Squared Error for each model\n",
    "print(\"Linear Regression MSE: \", lr_mse2)\n",
    "print(\"Random Forest Regressor MSE: \", rfr_mse2)\n",
    "print(\"Gradient Boosting Regressor MSE: \", gr_mse2)\n",
    "print(\"Decision Tree Regressor MSE: \", dt_mse2)\n",
    "\n",
    "# Print Mean Absolute Error for each model\n",
    "print(\"\\nLinear Regression MAE: \", lr_mae2)\n",
    "print(\"Random Forest Regressor MAE: \", rfr_mae2)\n",
    "print(\"Gradient Boosting Regressor MAE: \", gr_mae2)\n",
    "print(\"Decision Tree Regressor MAE: \", dt_mae2)\n",
    "\n",
    "# Print R2 Score for each model\n",
    "print(\"\\nLinear Regression R2 Score: \", lr_r2_2)\n",
    "print(\"Random Forest Regressor R2 Score: \", rfr_r2_2)\n",
    "print(\"Gradient Boosting Regressor R2 Score: \", gr_r2_2)\n",
    "print(\"Decision Tree Regressor R2 Score: \", dt_r2_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ea3b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table to compare the scores\n",
    "data = {\n",
    "    'Model': ['Linear Regression', 'Random Forest', 'Gradient Boosting', 'Decision Tree'],\n",
    "    'Mean Squared Error (MSE)': [lr_mse2, rfr_mse2, gr_mse2, dt_mse2],\n",
    "    'Mean Absolute Error (MAE)': [lr_mae2, rfr_mae2, gr_mae2, dt_mae2],\n",
    "    'R^2 Score': [lr_r2_2, rfr_r2_2, gr_r2_2, dt_r2_2]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f225670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prection on the test data. \n",
    "y_pred1 = lr.predict(X2_test)\n",
    "y_pred2 = rfr.predict(X2_test)\n",
    "y_pred3 = gr.predict(X2_test)\n",
    "y_pred4 = dt.predict(X2_test)\n",
    "df3 = pd.DataFrame({'Actual': Y2_test, 'Lr': y_pred1, 'rfr': y_pred2, 'gr': y_pred3,'dt':y_pred4,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b3ef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea10aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For rfr2 comparison\n",
    "plt.subplot()\n",
    "plt.plot(df3['Actual'].iloc[0:10], label='Actual')\n",
    "plt.plot(df3['rfr'].iloc[0:10], label=\"rfr\")\n",
    "plt.xlabel('Data Point')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Comparison - Actual vs rfr')\n",
    "plt.legend()\n",
    "\n",
    "# For Lr2 comparison\n",
    "plt.subplot()\n",
    "plt.plot(df3['Actual'].iloc[0:10], label='Actual')\n",
    "plt.plot(df3['Lr'].iloc[0:10], label=\"Lr\")\n",
    "plt.xlabel('Data Point')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Comparison - Actual vs Lr')\n",
    "plt.legend()\n",
    "\n",
    "# For gr2 comparison\n",
    "plt.subplot()\n",
    "plt.plot(df3['Actual'].iloc[0:10], label='Actual')\n",
    "plt.plot(df3['gr'].iloc[0:10], label=\"gr\")\n",
    "plt.xlabel('Data Point')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Comparison - Actual vs gr')\n",
    "plt.legend()\n",
    "\n",
    "# For dt2 comparison\n",
    "plt.subplot()\n",
    "plt.plot(df3['Actual'].iloc[0:10], label='Actual')\n",
    "plt.plot(df3['dt'].iloc[0:10], label=\"dt\")\n",
    "plt.xlabel('Data Point')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Comparison - Actual vs dt')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c766ce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating mean squared error (MSE) for each model\n",
    "mse_lr = mean_squared_error(df3['Actual'], df3['Lr'])\n",
    "mse_rfr = mean_squared_error(df3['Actual'], df3['rfr'])\n",
    "mse_gr = mean_squared_error(df3['Actual'], df3['gr'])\n",
    "mse_dt = mean_squared_error(df3['Actual'], df3['dt'])\n",
    "\n",
    "# dictionary that stores the MSE values\n",
    "mse_scores = {'Linear Regression': mse_lr,\n",
    "    'Random Forest': mse_rfr,\n",
    "    'Gradient Boosting': mse_gr,\n",
    "    'Decision Tree': mse_dt}\n",
    "\n",
    "# To find the best model \n",
    "best_model = min(mse_scores, key=mse_scores.get)\n",
    "\n",
    "print(\"The best model is:\", best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f4a02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 4, 6]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=RandomForestRegressor(), param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "grid_search.fit(X2_train, Y2_train)\n",
    "\n",
    "# Get the best hyperparameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print()\n",
    "\n",
    "# Train the best model on the entire training set\n",
    "best_model.fit(X2_train, Y2_train)\n",
    "\n",
    "# Evaluate the best model on the testing set\n",
    "best_predictions = best_model.predict(X2_test)\n",
    "best_mse = mean_squared_error(Y2_test, best_predictions)\n",
    "best_mae = mean_absolute_error(Y2_test, best_predictions)\n",
    "best_r2 = r2_score(Y2_test, best_predictions)\n",
    "\n",
    "print(\"Best Model Evaluation:\")\n",
    "print(\"MSE:\", best_mse)\n",
    "print(\"MAE:\", best_mae)\n",
    "print(\"R-squared:\", best_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958c8474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table to compare the scores\n",
    "data = {\n",
    "    'Model': ['Linear Regression', 'Random Forest', 'Gradient Boosting', 'Decision Tree'],\n",
    "    'Mean Squared Error (MSE)': [lr_mse2, rfr_mse2, gr_mse2, dt_mse2],\n",
    "    'Mean Absolute Error (MAE)': [lr_mae2, rfr_mae2, gr_mae2, dt_mae2],\n",
    "    'R^2 Score': [lr_r2_2, rfr_r2_2, gr_r2_2, dt_r2_2]}\n",
    "\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df3bb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0452aecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Predict= {'Location' : [3], \n",
    "               'MinTemp' : [13.4],\n",
    "               'MaxTemp'  : [22.9],\n",
    "               'WindGustDir' : [22.0],\n",
    "               'WindGustSpeed' :[1007.7],\n",
    "                'WindDir3pm' : [3],\n",
    "               'Windspeed9am' : [1.19],\n",
    "               'Windspeed3pm' : [13.00],\n",
    "               'WindDir9am' : [13],\n",
    "               'Humidity9am' : [4.0],\n",
    "               'Humidity3pm' : [25.0],\n",
    "               'Pressure9am' : ['1007.7'],\n",
    "               'Pressure3pm' : [1007.1],\n",
    "               'Temp9am' :  [16.9],\n",
    "               'Temp3pm' :  [21.8],\n",
    "               'RainToday' : [1],\n",
    "               'RainTomorrow' : [1]}\n",
    "\n",
    "df_pred = pd.DataFrame(data_Predict,index=[0])\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1760b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the result using the best model. \n",
    "new_pred = best_rf.predict(df_pred)\n",
    "print(new_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635632f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# saving the model. \n",
    "dump(best_rf, 'best_rf.joblib') \n",
    "\n",
    "# Loading the model\n",
    "best_rf_from_joblib = load('best_rf.joblib') \n",
    "\n",
    "# using the loaded model to make predictions\n",
    "best_rf_from_joblib.predict(X1_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
