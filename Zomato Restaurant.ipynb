{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31eea499",
   "metadata": {},
   "source": [
    "Zomato Restaurant"
   ]
  },
  {
   "cell_type": "raw",
   "id": "449020fb",
   "metadata": {},
   "source": [
    "Project Description\n",
    "Zomato Data Analysis is one of the most useful analysis for foodies who want to taste the best\n",
    "cuisines of every part of the world which lies in their budget. This analysis is also for those who\n",
    "want to find the value for money restaurants in various parts of the country for the cuisines.\n",
    "Additionally, this analysis caters the needs of people who are striving to get the best cuisine of\n",
    "the country and which locality of that country serves that cuisines with maximum number of\n",
    "restaurants.\n",
    "Data Storage:\n",
    "This problem statement contains two datasets- Zomato.csv and country_code.csv.\n",
    "Country_code.csv contains two variables:\n",
    " Country code\n",
    " Country name\n",
    "The collected data has been stored in the Comma Separated Value file Zomato.csv. Each\n",
    "restaurant in the dataset is uniquely identified by its Restaurant Id. Every Restaurant contains\n",
    "the following variables:\n",
    "• Restaurant Id: Unique id of every restaurant across various cities of the world\n",
    "• Restaurant Name: Name of the restaurant\n",
    "• Country Code: Country in which restaurant is located\n",
    "• City: City in which restaurant is located\n",
    "• Address: Address of the restaurant\n",
    "• Locality: Location in the city\n",
    "• Locality Verbose: Detailed description of the locality\n",
    "• Longitude: Longitude coordinate of the restaurant&amp;#39;s location\n",
    "• Latitude: Latitude coordinate of the restaurant&amp;#39;s location\n",
    "• Cuisines: Cuisines offered by the restaurant\n",
    "• Average Cost for two: Cost for two people in different currencies ��\n",
    "• Currency: Currency of the country\n",
    "• Has Table booking: yes/no\n",
    "• Has Online delivery: yes/ no\n",
    "• Is delivering: yes/ no\n",
    "• Switch to order menu: yes/no\n",
    "• Price range: range of price of food\n",
    "• Aggregate Rating: Average rating out of 5\n",
    "• Rating color: depending upon the average rating color\n",
    "• Rating text: text on the basis of rating of rating\n",
    "• Votes: Number of ratings casted by people\n",
    "Problem statement : In this dataset predict 2 things –\n",
    "1) Average Cost for two\n",
    "2) Price range\n",
    "\n",
    "Hint : Use pandas merge operation -- pd.merge (df1,df2) to combine two datasets\n",
    "\n",
    "Dataset Link-\n",
    " https://github.com/dsrscientist/dataset4/blob/main/Country-Code.xlsx\n",
    " https://github.com/dsrscientist/dataset4/blob/main/zomato.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50529641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a697c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df is the zomato csv and where as df1 represents the country. \n",
    "df = pd.read_csv('https://raw.githubusercontent.com/dsrscientist/dataset4/main/zomato.csv', encoding = \"ISO-8859-1\")\n",
    "df1 = pd.read_csv(r'C:/\\Users\\Country Head\\anaconda3\\Zomato.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b1de07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first 5 rows and all columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bab84bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the shape of the first dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a869ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysing the second dataframe\n",
    "df1.head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9de871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the shape of 2nd dataframe.\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c696e749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging both the datset based on the country code - the common parametre\n",
    "df = pd.merge(df, df1, on='Country Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b442f77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzing the final dataframe.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85834f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features\n",
    "X = df.drop(['Average Cost for two'], axis=1)\n",
    "y = df['Average Cost for two']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16b7d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().to_frame(\"No. of null values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69508247",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbafb74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Count unique occurrences of each location\n",
    "Country_counts = df['Country'].value_counts()\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the bar chart representing the locations\n",
    "plt.figure(figsize=(15,10))\n",
    "Country_counts.plot(kind='bar')\n",
    "plt.title('Bar chart of Locations')\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73388fb5",
   "metadata": {},
   "source": [
    " - representing the no null values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28da8bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the columns of the df\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c843136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# understanding the dataframe.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662c9aff",
   "metadata": {},
   "source": [
    "There are two types of data in the available in the datasete \n",
    "- object \n",
    "- int 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892e1341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the unique values and the count. \n",
    "for i in df.columns: \n",
    "    print(f\"columns:{i}\")\n",
    "    print(df[i].value_counts())\n",
    "    print(\"n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b7ed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We shall drop the Longitude and latitude since it is not adding any value to the output. \n",
    "df = df.drop(['Longitude', 'Latitude'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b648c014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorizing columns as categorical or numerical\n",
    "categorical_col = []\n",
    "numerical_col = []\n",
    "\n",
    "\n",
    "for i in df.columns:\n",
    "    if df.dtypes[i] == \"object\":\n",
    "        categorical_col.append(i)\n",
    "    else:\n",
    "        numerical_col.append(i)\n",
    "\n",
    "print(\"Categorical Columns:\", categorical_col)\n",
    "print(\"\\n\")\n",
    "print(\"Numerical Columns:\", numerical_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d962942e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the values of the categorical column\n",
    "le = LabelEncoder()\n",
    "for col in categorical_col:\n",
    "    df[col] = le.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011ba1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for the outliers in the dataframe.\n",
    "plt.figure(figsize =(10,6))\n",
    "plotnumber = 1\n",
    "\n",
    "for col in numerical_col:\n",
    "    if plotnumber<=9:\n",
    "        ax = plt.subplot(4,5,plotnumber)\n",
    "        sns.boxplot(df[col])\n",
    "        plt.xlabel(col,fontsize=15)\n",
    "        plt.xticks(rotation=0,fontsize=10)\n",
    "    plotnumber+=1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6446f783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the skewness of the categorical column. \n",
    "df[numerical_col].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57acf5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import pandas as pd\n",
    "from scipy.stats import yeojohnson\n",
    "# creating the a dataframe for the columns with skewness. \n",
    "skew_cols = ['Country Code', 'Aggregate rating', 'Votes','Country','Price range','Is delivering now',]\n",
    "\n",
    "# Applying to apply the Yeo-Johnson transformation method to the above df. \n",
    "for cols in skew_cols:\n",
    "    df[cols], _ = yeojohnson(df[cols])\n",
    "\n",
    "# Check the skewness after transformation\n",
    "print(df[skew_cols].skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265fca64",
   "metadata": {},
   "source": [
    "Working on the outliers using the Z score method and the IQR Method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866a512b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore \n",
    "feature_outliers = df[['Votes','Country Code','Aggregate rating','Average Cost for two','Price range']]\n",
    "z=np.abs(zscore(feature_outliers))\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d93f533",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping the threshold=3\n",
    "np.where(z>3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf322328",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.iloc[9397,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38fc6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning a new df for the values. \n",
    "df_new = df[(z < 3).all(axis=1)]\n",
    "print(df_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f560ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the Feature and the target. \n",
    "X = df.drop(columns='Average Cost for two',axis=1)\n",
    "Y = df['Average Cost for two']\n",
    "\n",
    "#Calculating z-scores\n",
    "z = np.abs(zscore(X))\n",
    "\n",
    "#Filtering features and target for z-scores less than 3\n",
    "X1 = X[(z < 3).all(axis=1)]\n",
    "Y1 = Y[(z < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9766de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the Shape of old and new dataframe\n",
    "print(\"old Data Frame : \",df.shape[0])\n",
    "print(\"New Data Frame : \",df_new.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7a22ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data Loss Percentage = \",((df.shape[0]-df_new.shape[0])/df.shape[0])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdce92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "for col in categorical_col:\n",
    "    df[col] = le.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98bdb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that the data loss percentange is high therefore we shall proceed without lossing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f57e95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ead4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100, 80))\n",
    "sns.pairplot(df,hue=\"Average Cost for two\",palette=\"Set1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd68c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(df.corr(), annot=True, fmt =\"0.2\", linecolor = \"black\",)\n",
    "plt.title(\"Correlation graph\")\n",
    "plt.xlabel('figure',fontsize=14)\n",
    "plt.ylabel('feature_label',fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca352c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(22, 7))\n",
    "df.corr()['Average Cost for two'].sort_values(ascending=False).drop('Average Cost for two').plot(kind='bar', color=\"m\")\n",
    "plt.xlabel('Feature', fontsize=15)\n",
    "plt.ylabel('Correlation with income', fontsize=15)\n",
    "plt.title('Correlation between Features and Income', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4e9720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "SPercentile = SelectPercentile(score_func=chi2, percentile=80)\n",
    "SPercentile = SPercentile.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76d6e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate the function to check the p value \n",
    "cols = SPercentile.get_support(indices=True)\n",
    "print ('Feature Index = ',cols)\n",
    "\n",
    "features = X.columns[cols]\n",
    "print('Features = ',list(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0a3a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = pd.DataFrame({'features': X.columns, 'Chi2Score': SPercentile.scores_, 'pValue': SPercentile.pvalues_})\n",
    "sorted_df_scores = df_scores.sort_values(by='Chi2Score', ascending=False)\n",
    "print(sorted_df_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4ba5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e1661d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features] # Remove the square brackets around 'W' and fix the axis argument\n",
    "y = df['Average Cost for two']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d6cfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a9c69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform feature scaling using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa73359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fitting the model\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "gr = GradientBoostingRegressor()\n",
    "gr.fit(X_train, y_train)\n",
    "\n",
    "dt = DecisionTreeRegressor()\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a40c37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prection on the test data. \n",
    "y_pred1 = lr.predict(X_test)\n",
    "y_pred2 = rfr.predict(X_test)\n",
    "y_pred3 = gr.predict(X_test)\n",
    "y_pred4 = dt.predict(X_test)\n",
    "df2 = pd.DataFrame({'Actual': y_test, 'Lr': y_pred1, 'rfr': y_pred2, 'gr': y_pred3,'dt':y_pred4,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5ae3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the models\n",
    "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
    "rfr_mse = mean_squared_error(y_test, rfr_predictions)\n",
    "gr_mse = mean_squared_error(y_test, gr_predictions)\n",
    "dt_mse = mean_squared_error(y_test, dt_predictions)\n",
    "\n",
    "lr_mae = mean_absolute_error(y_test, lr_predictions)\n",
    "rfr_mae = mean_absolute_error(y_test, rfr_predictions)\n",
    "gr_mae = mean_absolute_error(y_test, gr_predictions)\n",
    "dt_mae = mean_absolute_error(y_test, dt_predictions)\n",
    "\n",
    "lr_r2 = r2_score(y_test, lr_predictions)\n",
    "rfr_r2 = r2_score(y_test, rfr_predictions)\n",
    "gr_r2= r2_score(y_test, gr_predictions)\n",
    "dt_r2 = r2_score(y_test, dt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8808953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a321cc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(221)\n",
    "plt.plot(df2['Actual'].iloc[0:10], label='Actual')\n",
    "plt.plot(df2['rfr'].iloc[0:10], label=\"rfr\")\n",
    "plt.xlabel('Data Point')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Comparison - Actual vs rfr')\n",
    "plt.legend()\n",
    "\n",
    "# Repeat the above code for other subplots (222, 223, 224)\n",
    "plt.subplot(222)\n",
    "plt.plot(df2['Actual'].iloc[0:10], label='Actual')\n",
    "plt.plot(df2['Lr'].iloc[0:10], label=\"Lr\")\n",
    "plt.xlabel('Data Point')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Comparison - Actual vs Lr')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.plot(df2['Actual'].iloc[0:10], label='Actual')\n",
    "plt.plot(df2['gr'].iloc[0:10], label=\"gr\")\n",
    "plt.xlabel('Data Point')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Comparison - Actual vs gr')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.plot(df2['Actual'].iloc[0:10], label='Actual')\n",
    "plt.plot(df2['dt'].iloc[0:10], label=\"dt\")\n",
    "plt.xlabel('Data Point')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Comparison - Actual vs dt')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a3e3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating mean squared error (MSE) for each model\n",
    "mse_lr = mean_squared_error(df2['Actual'], df2['Lr'])\n",
    "mse_rfr = mean_squared_error(df2['Actual'], df2['rfr'])\n",
    "mse_gr = mean_squared_error(df2['Actual'], df2['gr'])\n",
    "mse_dt = mean_squared_error(df2['Actual'], df2['dt'])\n",
    "\n",
    "# dictionary that stores the MSE values\n",
    "mse_scores = {\n",
    "    'Linear Regression': mse_lr,\n",
    "    'Random Forest': mse_rfr,\n",
    "    'Gradient Boosting': mse_gr,\n",
    "    'Decision Tree': mse_dt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8540b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Assuming 'lr', 'rfr', 'gr', 'dt' are your trained models\n",
    "models = {'Linear Regression': lr, 'Random Forest Regressor': rfr, 'Gradient Boosting Regressor': gr, 'Decision Tree Regressor': dt}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    print(f\"Cross-Validation Scores for {model_name}: \", scores)\n",
    "    print(f\"Average Cross-Validation Score for {model_name}: \", scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6a4e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "rfr = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# Define a grid of hyperparameter 'params_\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200], \n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(estimator=rfr, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "grid_rf.fit(X_train, y_train)\n",
    "print(\"Best parameters found: \", grid_rf.best_params_)\n",
    "print(\"Best score found: \", grid_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3044c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best parameters\n",
    "best_params = grid_rf.best_params_\n",
    "print(\"Best parameters found: \", best_params)\n",
    "\n",
    "# Get the best score\n",
    "best_score = grid_rf.best_score_\n",
    "print(\"Best score found: \", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752a5b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find the best model \n",
    "best_rf = min(mse_scores, key=mse_scores.get)\n",
    "best_rf.fit(X_train, y_train)\n",
    "print(\"The best model is:\", best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bd9c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Predict= {'Restaurant ID':[6304287],\n",
    "               'Restaurant Name':[5523],\n",
    "               'Country Code': [162],\n",
    "               'City' :[75],\n",
    "               'Address':[4684],\n",
    "               'Locality':[398],\n",
    "               'Locality Verbose': [314],\n",
    "               'Cuisines': [1111],\n",
    "               'Average Cost for two': [1200],\n",
    "               'Currency': [0],\n",
    "               'Has Table booking': [1],\n",
    "               'Has Online delivery':[0],\n",
    "               'Is delivering now':[1],\n",
    "               'Switch to order menu':[1],\n",
    "               'Price range' :[4],\n",
    "               'Aggregate rating':[4.9],\n",
    "               'Rating color':[1],\n",
    "               'Rating text':[1],\n",
    "               'Votes': [365],\n",
    "               'Country': [6]}\n",
    "\n",
    "df_pred = pd.DataFrame(data_Predict,index=[0])\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed184cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the result using the best model. \n",
    "new_pred = best_rfr.predict(df_pred)\n",
    "print(new_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b0e3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# saving the model. \n",
    "dump(best_rf, 'best_rf.joblib') \n",
    "\n",
    "# Loading the model\n",
    "best_rf_from_joblib = load('best_rf.joblib') \n",
    "\n",
    "# using the loaded model to make predictions\n",
    "best_rf_from_joblib.predict(X1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c219a18f",
   "metadata": {},
   "source": [
    "- Price range ( 2nd Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68951265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the Next Tmin value \n",
    "X2 = df.drop(['Price range'],axis=1)\n",
    "y2 = df['Price range']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f6934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, Y2_train, Y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling the data\n",
    "scaler = StandardScaler()\n",
    "X2_train_scaled = scaler.fit_transform(X2_train)\n",
    "X2_test_scaled = scaler.transform(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b72357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "X2_train, X2_test, Y2_train, Y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8f93c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining and fitting the model \n",
    "lr = LinearRegression()\n",
    "lr.fit(X2_train_scaled, Y2_train)\n",
    "\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X2_train_scaled, Y2_train)\n",
    "\n",
    "gr = GradientBoostingRegressor()\n",
    "gr.fit(X2_train_scaled, Y2_train)\n",
    "\n",
    "dt = DecisionTreeRegressor()\n",
    "dt.fit(X2_train_scaled, Y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0afa33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions on the test data\n",
    "lr_predictions = lr.predict(X2_test)\n",
    "rfr_predictions = rfr.predict(X2_test)\n",
    "gr_predictions = gr.predict(X2_test)\n",
    "dt_predictions = dt.predict(X2_test)\n",
    "\n",
    "# Evaluating the models\n",
    "lr_mse2 = mean_squared_error(Y2_test, lr_predictions)\n",
    "rfr_mse2 = mean_squared_error(Y2_test, rfr_predictions)\n",
    "gr_mse2 = mean_squared_error(Y2_test, gr_predictions)\n",
    "dt_mse2 = mean_squared_error(Y2_test, dt_predictions)\n",
    "\n",
    "lr_mae2 = mean_absolute_error(Y2_test, lr_predictions)\n",
    "rfr_mae2 = mean_absolute_error(Y2_test, rfr_predictions)\n",
    "gr_mae2 = mean_absolute_error(Y2_test, gr_predictions)\n",
    "dt_mae2 = mean_absolute_error(Y2_test, dt_predictions)\n",
    "\n",
    "lr_r2_2 = r2_score(Y2_test, lr_predictions)\n",
    "rfr_r2_2 = r2_score(Y2_test, rfr_predictions)\n",
    "gr_r2_2= r2_score(Y2_test, gr_predictions)\n",
    "dt_r2_2 = r2_score(Y2_test, dt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7fec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Mean Squared Error for each model\n",
    "print(\"Linear Regression MSE: \", lr_mse2)\n",
    "print(\"Random Forest Regressor MSE: \", rfr_mse2)\n",
    "print(\"Gradient Boosting Regressor MSE: \", gr_mse2)\n",
    "print(\"Decision Tree Regressor MSE: \", dt_mse2)\n",
    "\n",
    "# Print Mean Absolute Error for each model\n",
    "print(\"\\nLinear Regression MAE: \", lr_mae2)\n",
    "print(\"Random Forest Regressor MAE: \", rfr_mae2)\n",
    "print(\"Gradient Boosting Regressor MAE: \", gr_mae2)\n",
    "print(\"Decision Tree Regressor MAE: \", dt_mae2)\n",
    "\n",
    "# Print R2 Score for each model\n",
    "print(\"\\nLinear Regression R2 Score: \", lr_r2_2)\n",
    "print(\"Random Forest Regressor R2 Score: \", rfr_r2_2)\n",
    "print(\"Gradient Boosting Regressor R2 Score: \", gr_r2_2)\n",
    "print(\"Decision Tree Regressor R2 Score: \", dt_r2_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bc654b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table to compare the scores\n",
    "data = {\n",
    "    'Model': ['Linear Regression', 'Random Forest', 'Gradient Boosting', 'Decision Tree'],\n",
    "    'Mean Squared Error (MSE)': [lr_mse2, rfr_mse2, gr_mse2, dt_mse2],\n",
    "    'Mean Absolute Error (MAE)': [lr_mae2, rfr_mae2, gr_mae2, dt_mae2],\n",
    "    'R^2 Score': [lr_r2_2, rfr_r2_2, gr_r2_2, dt_r2_2]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e6f887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prection on the test data. \n",
    "y_pred1 = lr.predict(X2_test)\n",
    "y_pred2 = rfr.predict(X2_test)\n",
    "y_pred3 = gr.predict(X2_test)\n",
    "y_pred4 = dt.predict(X2_test)\n",
    "df3 = pd.DataFrame({'Actual': Y2_test, 'Lr': y_pred1, 'rfr': y_pred2, 'gr': y_pred3,'dt':y_pred4,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4ce745",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fc3879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For rfr2 comparison\n",
    "plt.subplot()\n",
    "plt.plot(df3['Actual'].iloc[0:10], label='Actual')\n",
    "plt.plot(df3['rfr'].iloc[0:10], label=\"rfr\")\n",
    "plt.xlabel('Data Point')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Comparison - Actual vs rfr')\n",
    "plt.legend()\n",
    "\n",
    "# For Lr2 comparison\n",
    "plt.subplot()\n",
    "plt.plot(df3['Actual'].iloc[0:10], label='Actual')\n",
    "plt.plot(df3['Lr'].iloc[0:10], label=\"Lr\")\n",
    "plt.xlabel('Data Point')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Comparison - Actual vs Lr')\n",
    "plt.legend()\n",
    "\n",
    "# For gr2 comparison\n",
    "plt.subplot()\n",
    "plt.plot(df3['Actual'].iloc[0:10], label='Actual')\n",
    "plt.plot(df3['gr'].iloc[0:10], label=\"gr\")\n",
    "plt.xlabel('Data Point')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Comparison - Actual vs gr')\n",
    "plt.legend()\n",
    "\n",
    "# For dt2 comparison\n",
    "plt.subplot()\n",
    "plt.plot(df3['Actual'].iloc[0:10], label='Actual')\n",
    "plt.plot(df3['dt'].iloc[0:10], label=\"dt\")\n",
    "plt.xlabel('Data Point')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Comparison - Actual vs dt')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d9ceea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating mean squared error (MSE) for each model\n",
    "mse_lr = mean_squared_error(df3['Actual'], df3['Lr'])\n",
    "mse_rfr = mean_squared_error(df3['Actual'], df3['rfr'])\n",
    "mse_gr = mean_squared_error(df3['Actual'], df3['gr'])\n",
    "mse_dt = mean_squared_error(df3['Actual'], df3['dt'])\n",
    "\n",
    "# dictionary that stores the MSE values\n",
    "mse_scores = {'Linear Regression': mse_lr,\n",
    "    'Random Forest': mse_rfr,\n",
    "    'Gradient Boosting': mse_gr,\n",
    "    'Decision Tree': mse_dt}\n",
    "\n",
    "# To find the best model \n",
    "best_model = min(mse_scores, key=mse_scores.get)\n",
    "\n",
    "print(\"The best model is:\", best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c56a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 4, 6]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=RandomForestRegressor(), param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "grid_search.fit(X2_train, Y2_train)\n",
    "\n",
    "# Get the best hyperparameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print()\n",
    "\n",
    "# Train the best model on the entire training set\n",
    "best_model.fit(X2_train, Y2_train)\n",
    "\n",
    "# Evaluate the best model on the testing set\n",
    "best_predictions = best_model.predict(X2_test)\n",
    "best_mse = mean_squared_error(Y2_test, best_predictions)\n",
    "best_mae = mean_absolute_error(Y2_test, best_predictions)\n",
    "best_r2 = r2_score(Y2_test, best_predictions)\n",
    "\n",
    "print(\"Best Model Evaluation:\")\n",
    "print(\"MSE:\", best_mse)\n",
    "print(\"MAE:\", best_mae)\n",
    "print(\"R-squared:\", best_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa87112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table to compare the scores\n",
    "data = {\n",
    "    'Model': ['Linear Regression', 'Random Forest', 'Gradient Boosting', 'Decision Tree'],\n",
    "    'Mean Squared Error (MSE)': [lr_mse2, rfr_mse2, gr_mse2, dt_mse2],\n",
    "    'Mean Absolute Error (MAE)': [lr_mae2, rfr_mae2, gr_mae2, dt_mae2],\n",
    "    'R^2 Score': [lr_r2_2, rfr_r2_2, gr_r2_2, dt_r2_2]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6911ed2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbfe57f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a493d6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best parameters\n",
    "best_params = grid_rf.best_params_\n",
    "print(\"Best parameters found: \", best_params)\n",
    "\n",
    "# Get the best score\n",
    "best_score = grid_rf.best_score_\n",
    "print(\"Best score found: \", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae66f245",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7b42d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Predict= {'Restaurant ID':[6304287],\n",
    "               'Restaurant Name':[5523],\n",
    "               'Country Code': [162],\n",
    "               'City' :[75],\n",
    "               'Address':[4684],\n",
    "               'Locality':[398],\n",
    "               'Locality Verbose': [314],\n",
    "               'Cuisines': [1111],\n",
    "               'Average Cost for two': [1200],\n",
    "               'Currency': [0],\n",
    "               'Has Table booking': [1],\n",
    "               'Has Online delivery':[0],\n",
    "               'Is delivering now':[1],\n",
    "               'Switch to order menu':[1],\n",
    "               'Price range' :[4],\n",
    "               'Aggregate rating':[4.9],\n",
    "               'Rating color':[1],\n",
    "               'Rating text':[1],\n",
    "               'Votes': [365],\n",
    "               'Country' : [6]}\n",
    "\n",
    "df_pred = pd.DataFrame(data_Predict,index=[0])\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c725332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "rfr = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# Define a grid of hyperparameter 'params_\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200], \n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(estimator=rfr, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "grid_rf.fit(X_train, y_train)\n",
    "print(\"Best parameters found: \", grid_rf.best_params_)\n",
    "print(\"Best score found: \", grid_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5db6ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the result using the best model. \n",
    "new_pred = best_rfr.predict(df_pred)\n",
    "print(new_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13168b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# saving the model. \n",
    "dump(best_rf, 'best_rf.joblib') \n",
    "\n",
    "# Loading the model\n",
    "best_rf_from_joblib = load('best_rf.joblib') \n",
    "\n",
    "# using the loaded model to make predictions\n",
    "best_rf_from_joblib.predict(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bc1857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923a609a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad249d26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c53791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227bfec5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
